new_column_names <- c("ID", "Limited_Bal", "Gender", "Education", "Marriage", "Age", "Repay_Sept", "Repay_Aug", "Repay_Jul", "Repay_Jun", "Repay_May", "Repay_Apr", "Billpay_Sept", "Billpay_Aug", "Billpay_Jul", "Billpay_Jun", "Billpay_May", "Billpay_Apr", "Amtpaid_Sept", "Amtpaid_Aug", "Amtpaid_Jul", "Amtpaid_Jun", "Amtpaid_May", "Amtpaid_Apr", "default_payment_next_month")
# Rename the columns
colnames(data) <- new_column_names
# Define the new order of columns
new_column_order <- c("ID", "Limited_Bal", "Gender", "Education", "Marriage", "Age", "Repay_Apr", "Repay_May", "Repay_Jun", "Repay_Jul", "Repay_Aug", "Repay_Sept","Billpay_Apr", "Billpay_May", "Billpay_Jun", "Billpay_Jul", "Billpay_Aug", "Billpay_Sept", "Amtpaid_Apr", "Amtpaid_May", "Amtpaid_Jun", "Amtpaid_Jul", "Amtpaid_Aug", "Amtpaid_Sept", "default_payment_next_month")
# Reorder the columns
final_data <- select(data, all_of(new_column_order))
final_data <- final_data %>%
mutate(Gender = recode(Gender,
"1" = "Male",
"2" = "Female"))
# Recode Education column based on the specified mapping
final_data <- final_data %>%
mutate(Education = recode(Education,
"0" = "Unknown",
"1" = "Grad",
"2" = "University",
"3" = "High_school",
"4" = "Others",
"5" = "PG",
"6" = "Advanced_degree"))
final_data <- final_data %>%
mutate(Marriage = recode(Marriage,
"0" = "Unknown",
"1" = "Married",
"2" = "Single",
"3" = "Others"))
final_data <- final_data %>%
mutate(default_payment_next_month = recode(default_payment_next_month,
"0" = "Not Default",
"1" = "Default"))
final_data$Repay_Apr <- as.factor(final_data$Repay_Apr)
final_data$Repay_May <- as.factor(final_data$Repay_May)
final_data$Repay_Jun <- as.factor(final_data$Repay_Jun)
final_data$Repay_Jul <- as.factor(final_data$Repay_Jul)
final_data$Repay_Aug <- as.factor(final_data$Repay_Aug)
final_data$Repay_Sept <- as.factor(final_data$Repay_Sept)
head(final_data)
plot1 = ggplot(final_data, aes(x = Age, y = Limited_Bal)) +
geom_point() +
geom_smooth(aes(color = Education)) +
scale_color_manual(values = c("High_school" = "yellow", "University" =   "brown","Grad" = "green", "Others" = "purple", "Advanced_degree" = "red", "PG" = "blue", "Unknown" = "darkgreen")) +
labs(title = "Relationship between Age and Limited Balance by Education",
x = "Age (years)", y = "Credit Limit", color = "Education") +
facet_wrap(~Education)
ggplotly(plot1)
library(dplyr)
library(tidyselect)
library(tidyverse)
library(plotly)
# Set the file path
file_path <- "C:\\Users\\nmadh\\OneDrive\\Desktop\\Credit card defaults .csv"
# Read the CSV file, excluding the first row
data <- read.csv(file_path, skip = 1)
# Define the new column names
new_column_names <- c("ID", "Limited_Bal", "Gender", "Education", "Marriage", "Age", "Repay_Sept", "Repay_Aug", "Repay_Jul", "Repay_Jun", "Repay_May", "Repay_Apr", "Billpay_Sept", "Billpay_Aug", "Billpay_Jul", "Billpay_Jun", "Billpay_May", "Billpay_Apr", "Amtpaid_Sept", "Amtpaid_Aug", "Amtpaid_Jul", "Amtpaid_Jun", "Amtpaid_May", "Amtpaid_Apr", "default_payment_next_month")
# Rename the columns
colnames(data) <- new_column_names
# Define the new order of columns
new_column_order <- c("ID", "Limited_Bal", "Gender", "Education", "Marriage", "Age", "Repay_Apr", "Repay_May", "Repay_Jun", "Repay_Jul", "Repay_Aug", "Repay_Sept","Billpay_Apr", "Billpay_May", "Billpay_Jun", "Billpay_Jul", "Billpay_Aug", "Billpay_Sept", "Amtpaid_Apr", "Amtpaid_May", "Amtpaid_Jun", "Amtpaid_Jul", "Amtpaid_Aug", "Amtpaid_Sept", "default_payment_next_month")
# Reorder the columns
final_data <- select(data, all_of(new_column_order))
final_data <- final_data %>%
mutate(Gender = recode(Gender,
"1" = "Male",
"2" = "Female"))
# Recode Education column based on the specified mapping
final_data <- final_data %>%
mutate(Education = recode(Education,
"0" = "Unknown",
"1" = "Grad",
"2" = "University",
"3" = "High_school",
"4" = "Others",
"5" = "PG",
"6" = "Advanced_degree"))
final_data <- final_data %>%
mutate(Marriage = recode(Marriage,
"0" = "Unknown",
"1" = "Married",
"2" = "Single",
"3" = "Others"))
final_data <- final_data %>%
mutate(default_payment_next_month = recode(default_payment_next_month,
"0" = "Not Default",
"1" = "Default"))
final_data$Repay_Apr <- as.factor(final_data$Repay_Apr)
final_data$Repay_May <- as.factor(final_data$Repay_May)
final_data$Repay_Jun <- as.factor(final_data$Repay_Jun)
final_data$Repay_Jul <- as.factor(final_data$Repay_Jul)
final_data$Repay_Aug <- as.factor(final_data$Repay_Aug)
final_data$Repay_Sept <- as.factor(final_data$Repay_Sept)
knitr::kable(final_data, row.names=FALSE)
# Correlation Matrix
# Ensure column names match with the ones you're using
colnames(credit_data)
# Correlation Matrix
# Read the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# Ensure column names match with the ones you're using
colnames(credit_data)
# Compute the correlation matrix
correlation_matrix <- cor(credit_data[, c("Limited_Bal", "Age", "Repay_Apr", "Repay_May", "Repay_Jun", "Repay_Jul", "Repay_Aug", "Repay_Sept", "Billpay_Apr", "Billpay_May", "Billpay_Jun", "Billpay_Jul", "Billpay_Aug", "Billpay_Sept", "Amtpaid_Apr", "Amtpaid_May", "Amtpaid_Jun", "Amtpaid_Jul", "Amtpaid_Aug", "Amtpaid_Sept")])
# Load the corrplot package
library(corrplot)
# Plot the correlation matrix
corrplot(correlation_matrix)
data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv");
head(data)
data$Gender<- factor(data$Gender)
data$Education <- factor(data$Education)
data$Marriage <- factor(data$Marriage)
data$Repay_Sept <- factor(data$Repay_Sept)
data$Repay_Aug <- factor(data$Repay_Aug)
data$Repay_Jul <- factor(data$Repay_Jul)
data$Repay_Jun <- factor(data$Repay_Jun)
data$Repay_May <- factor(data$Repay_May)
data$Repay_Apr <- factor(data$Repay_Apr)
data$default_payment_next_month <- factor(data$default_payment_next_month)
# Load required libraries
library(randomForest)
# Set seed for reproducibility
set.seed(1234)
# Train the Random Forest model
rf_model <- randomForest(default_payment_next_month ~ ., data = data)
# Get variable importance measures
importance <- importance(rf_model)
# Sort variable importance measures by importance
var_importance <- importance[order(-importance[, 1]), ]
# Display variable importance measures
print(var_importance)
str(importance)
# Check the structure of the importance object
# Extract the values of MeanDecreaseGini
importance_values <- as.numeric(importance[, 1])
# Plot feature importance
barplot(importance_values,
main = "Feature Importance in Predicting Credit Default Risk",
xlab = "Features",
ylab = "Mean Decrease in Gini Index",
cex.names = 0.8,
las = 2,  # Rotate labels vertically
col = "skyblue",
ylim = c(0, max(importance_values) * 1.1),
names.arg = rownames(importance))
# Extract the values of MeanDecreaseGini
importance_values <- as.numeric(importance[, 1])
# Sort feature importance values in descending order
importance_values_sorted <- sort(importance_values, decreasing = TRUE)
# Get corresponding feature names
feature_names <- rownames(importance)[order(importance_values, decreasing = TRUE)]
# Plot feature importance
barplot(importance_values_sorted,
main = "Feature Importance in Predicting Credit Default Risk",
xlab = "Features",
ylab = "Mean Decrease in Gini Index",
cex.names = 0.8,
las = 2,  # Rotate labels vertically
col = "skyblue",
ylim = c(0, max(importance_values_sorted) * 1.1),
names.arg = feature_names,
args.legend = list(x = "topright"),  # Adjust x-axis label position
mar = c(10, 10, 14, 12))  # Adjust margin (bottom margin increased)
data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
data$Gender<- factor(data$Gender)
data$Education <- factor(data$Education)
data$Marriage <- factor(data$Marriage)
data$Repay_Sept <- factor(data$Repay_Sept)
data$Repay_Aug <- factor(data$Repay_Aug)
data$Repay_Jul <- factor(data$Repay_Jul)
data$Repay_Jun <- factor(data$Repay_Jun)
data$Repay_May <- factor(data$Repay_May)
data$Repay_Apr <- factor(data$Repay_Apr)
data$default_payment_next_month <- factor(data$default_payment_next_month)
# Load required libraries
library(randomForest)
# Set seed for reproducibility
set.seed(1234)
# Train the Random Forest model
rf_model <- randomForest(default_payment_next_month ~ ., data = data)
# Get variable importance measures
importance <- importance(rf_model)
# Sort variable importance measures by importance
var_importance <- importance[order(-importance[, 1]), ]
# Display variable importance measures
print(var_importance)
str(importance)
# Check the structure of the importance object
# Extract the values of MeanDecreaseGini
importance_values <- as.numeric(importance[, 1])
# Plot feature importance
barplot(importance_values,
main = "Feature Importance in Predicting Credit Default Risk",
xlab = "Features",
ylab = "Mean Decrease in Gini Index",
cex.names = 0.8,
las = 2,  # Rotate labels vertically
col = "skyblue",
ylim = c(0, max(importance_values) * 1.1),
names.arg = rownames(importance))
# Extract the values of MeanDecreaseGini
importance_values <- as.numeric(importance[, 1])
# Sort feature importance values in descending order
importance_values_sorted <- sort(importance_values, decreasing = TRUE)
# Get corresponding feature names
feature_names <- rownames(importance)[order(importance_values, decreasing = TRUE)]
# Plot feature importance
barplot(importance_values_sorted,
main = "Feature Importance in Predicting Credit Default Risk",
xlab = "Features",
ylab = "Mean Decrease in Gini Index",
cex.names = 0.8,
las = 2,  # Rotate labels vertically
col = "skyblue",
ylim = c(0, max(importance_values_sorted) * 1.1),
names.arg = feature_names,
args.legend = list(x = "topright"),  # Adjust x-axis label position
mar = c(10, 10, 14, 12))  # Adjust margin (bottom margin increased)
plot1 = ggplot(credit_data, aes(x = default_payment_next_month, fill = Gender)) +
geom_bar() +
facet_wrap(~ Education + Marriage, scales = "free") +
labs(title = "Default Payments by Gender, Education, and Marriage Status")
library(readr)  # For data reading
library(dplyr)  # For data manipulation
library(ggplot2)  # For data visualization
library(caret)
plot1 = ggplot(credit_data, aes(x = default_payment_next_month, fill = Gender)) +
geom_bar() +
facet_wrap(~ Education + Marriage, scales = "free") +
labs(title = "Default Payments by Gender, Education, and Marriage Status")
plot1
confusionMatrix(table(predicted_classes, test_data$default_payment_next_month))
# Load necessary libraries
library(readr)  # For data reading
library(dplyr)  # For data manipulation
library(ggplot2)  # For data visualization
library(caret)  # For machine learning models
# Read the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# 1. Preprocess the data
# Convert categorical variables to factors
credit_data$Gender <- as.factor(credit_data$Gender)
credit_data$Education <- as.factor(credit_data$Education)
credit_data$Marriage <- as.factor(credit_data$Marriage)
credit_data$default_payment_next_month <- as.factor(credit_data$default_payment_next_month)
# Check for missing values
sum(is.na(credit_data))
# 2. Explore the data
# Visualize default payments across different demographic groups
plot1 = ggplot(credit_data, aes(x = default_payment_next_month, fill = Gender)) +
geom_bar() +
facet_wrap(~ Education + Marriage, scales = "free") +
labs(title = "Default Payments by Gender, Education, and Marriage Status")
plot1
# 3. Train regression models
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(credit_data$default_payment_next_month, p = 0.7, list = FALSE)
train_data <- credit_data[train_index, ]
test_data <- credit_data[-train_index, ]
# Train logistic regression model
logit_model <- glm(default_payment_next_month ~ ., data = train_data, family = binomial)
# 4. Evaluate model performance
# Make predictions on the test set
predictions <- predict(logit_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(predictions > 0.5, "Default", "Not Default")
# Confusion matrix
confusionMatrix(table(predicted_classes, test_data$default_payment_next_month))
data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
data$Gender<- factor(data$Gender)
data$Education <- factor(data$Education)
data$Marriage <- factor(data$Marriage)
data$Repay_Sept <- factor(data$Repay_Sept)
data$Repay_Aug <- factor(data$Repay_Aug)
data$Repay_Jul <- factor(data$Repay_Jul)
data$Repay_Jun <- factor(data$Repay_Jun)
data$Repay_May <- factor(data$Repay_May)
data$Repay_Apr <- factor(data$Repay_Apr)
data$default_payment_next_month <- factor(data$default_payment_next_month)
# Load required libraries
library(randomForest)
# Set seed for reproducibility
set.seed(1234)
# Train the Random Forest model
rf_model <- randomForest(default_payment_next_month ~ ., data = data)
# Get variable importance measures
importance <- importance(rf_model)
# Sort variable importance measures by importance
var_importance <- importance[order(-importance[, 1]), ]
# Display variable importance measures
print(var_importance)
# Load necessary libraries
library(readr)  # For data reading
library(dplyr)  # For data manipulation
library(ggplot2)  # For data visualization
library(caret)  # For machine learning models
# Read the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# 1. Preprocess the data
# Convert categorical variables to factors
credit_data$Gender <- as.factor(credit_data$Gender)
credit_data$Education <- as.factor(credit_data$Education)
credit_data$Marriage <- as.factor(credit_data$Marriage)
credit_data$default_payment_next_month <- as.factor(credit_data$default_payment_next_month)
# Check for missing values
sum(is.na(credit_data))
# 2. Explore the data
# Visualize default payments across different demographic groups
plot1 = ggplot(credit_data, aes(x = default_payment_next_month, fill = Gender)) +
geom_bar() +
facet_wrap(~ Education + Marriage, scales = "free") +
labs(title = "Default Payments by Gender, Education, and Marriage Status")
plot1
# 3. Train regression models
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(credit_data$default_payment_next_month, p = 0.7, list = FALSE)
train_data <- credit_data[train_index, ]
test_data <- credit_data[-train_index, ]
# Train logistic regression model
logit_model <- glm(default_payment_next_month ~ ., data = train_data, family = binomial)
# 4. Evaluate model performance
# Make predictions on the test set
predictions <- predict(logit_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(predictions > 0.5, "Default", "Not Default")
# Confusion matrix
confusionMatrix(table(predicted_classes, test_data$default_payment_next_month))
# Load necessary libraries
library(readr)  # For data reading
library(dplyr)  # For data manipulation
library(ggplot2)  # For data visualization
library(caret)  # For machine learning models
# Read the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# 1. Preprocess the data
# Convert categorical variables to factors
credit_data$Gender <- as.factor(credit_data$Gender)
credit_data$Education <- as.factor(credit_data$Education)
credit_data$Marriage <- as.factor(credit_data$Marriage)
credit_data$default_payment_next_month <- as.factor(credit_data$default_payment_next_month)
# Check for missing values
sum(is.na(credit_data))
# 3. Train regression models
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(credit_data$default_payment_next_month, p = 0.7, list = FALSE)
train_data <- credit_data[train_index, ]
test_data <- credit_data[-train_index, ]
# Train logistic regression model
logit_model <- glm(default_payment_next_month ~ ., data = train_data, family = binomial)
# 4. Evaluate model performance
# Make predictions on the test set
predictions <- predict(logit_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(predictions > 0.5, "Default", "Not Default")
# Confusion matrix
confusionMatrix(table(predicted_classes, test_data$default_payment_next_month))
# Load necessary libraries
library(readr)  # For data reading
library(dplyr)  # For data manipulation
library(ggplot2)  # For data visualization
library(caret)  # For machine learning models
# Read the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# 1. Preprocess the data
# Convert categorical variables to factors
credit_data$Gender <- as.factor(credit_data$Gender)
credit_data$Education <- as.factor(credit_data$Education)
credit_data$Marriage <- as.factor(credit_data$Marriage)
credit_data$default_payment_next_month <- as.factor(credit_data$default_payment_next_month)
# Check for missing values
sum(is.na(credit_data))
# 3. Train regression models
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(credit_data$default_payment_next_month, p = 0.7, list = FALSE)
train_data <- credit_data[train_index, ]
test_data <- credit_data[-train_index, ]
# Train logistic regression model
logit_model <- glm(default_payment_next_month ~ ., data = train_data, family = binomial)
# 4. Evaluate model performance
# Make predictions on the test set
predictions <- predict(logit_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(predictions > 0.5, "Default", "Not Default")
# Confusion matrix
confusionMatrix(table(predicted_classes, test_data$default_payment_next_month))
data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
data$Gender<- factor(data$Gender)
data$Education <- factor(data$Education)
data$Marriage <- factor(data$Marriage)
data$Repay_Sept <- factor(data$Repay_Sept)
data$Repay_Aug <- factor(data$Repay_Aug)
data$Repay_Jul <- factor(data$Repay_Jul)
data$Repay_Jun <- factor(data$Repay_Jun)
data$Repay_May <- factor(data$Repay_May)
data$Repay_Apr <- factor(data$Repay_Apr)
data$default_payment_next_month <- factor(data$default_payment_next_month)
# Load required libraries
library(randomForest)
# Set seed for reproducibility
set.seed(1234)
# Train the Random Forest model
rf_model <- randomForest(default_payment_next_month ~ ., data = data)
# Get variable importance measures
importance <- importance(rf_model)
# Sort variable importance measures by importance
var_importance <- importance[order(-importance[, 1]), ]
# Display variable importance measures
print(var_importance)
# Load necessary libraries
library(readr)  # For data reading
library(dplyr)  # For data manipulation
library(ggplot2)  # For data visualization
library(caret)  # For machine learning models
# Read the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# 1. Preprocess the data
# Convert categorical variables to factors
credit_data$Gender <- as.factor(credit_data$Gender)
credit_data$Education <- as.factor(credit_data$Education)
credit_data$Marriage <- as.factor(credit_data$Marriage)
credit_data$default_payment_next_month <- as.factor(credit_data$default_payment_next_month)
# 3. Train regression models
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(credit_data$default_payment_next_month, p = 0.7, list = FALSE)
train_data <- credit_data[train_index, ]
test_data <- credit_data[-train_index, ]
# Train logistic regression model
logit_model <- glm(default_payment_next_month ~ ., data = train_data, family = binomial)
# 4. Evaluate model performance
# Make predictions on the test set
predictions <- predict(logit_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(predictions > 0.5, "Default", "Not Default")
# Confusion matrix
confusionMatrix(table(predicted_classes, test_data$default_payment_next_month))
# Load necessary libraries
library(cluster)
# Load the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# Step 2: Select relevant columns for clustering
data_for_clustering <- credit_data[, c("Limited_Bal", "Repay_Apr", "Repay_May", "Repay_Jun", "Repay_Jul", "Repay_Aug", "Repay_Sept")]
# Step 3: Standardize the data
scaled_data <- scale(data_for_clustering)
# Step 4: Determine optimal number of clusters using elbow method
wss <- (nrow(scaled_data)-1) * sum(apply(scaled_data, 2, var))
for (i in 2:15) wss[i] <- sum(kmeans(scaled_data, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
# Step 5: Based on the elbow plot, select the number of clusters (e.g., 3)
num_clusters <- 3
# Step 6: Perform K-means clustering
kmeans_result <- kmeans(scaled_data, centers=num_clusters)
# Step 7: Assign cluster labels to each user
cluster_labels <- kmeans_result$cluster
# Step 8: Add cluster labels to the original dataset
credit_data_with_clusters <- cbind(credit_data, cluster = cluster_labels)
# Step 9: Get the cluster centers
cluster_centers <- kmeans_result$centers
# Step 10: Calculate standard deviations across columns
col_std_dev <- apply(data_for_clustering, 2, sd)
# Step 11: Scale the cluster centers by dividing by standard deviations
cluster_centers <- scale(cluster_centers, center = FALSE, scale = col_std_dev)
# Step 12: Assign column names to cluster_centers
colnames(cluster_centers) <- colnames(data_for_clustering)
# Step 13: View cluster centers
print(cluster_centers)
# Visualization (Optional):
# Plot clusters based on the first two principal components
pca_data <- prcomp(scaled_data, center = TRUE, scale. = TRUE)
plot(pca_data$x[, 1], pca_data$x[, 2], col = cluster_labels, pch = 20, main = "Clusters based on Credit Utilization Patterns", xlab = "Principal Component 1", ylab = "Principal Component 2")
legend("topright", legend = unique(cluster_labels), col = unique(cluster_labels), pch = 20, title = "Cluster")
# Load necessary libraries
library(cluster)
# Load the dataset
credit_data <- read.csv("C:\\Users\\nmadh\\OneDrive\\Desktop\\Final Project\\Final_output.csv")
# Step 2: Select relevant columns for clustering
data_for_clustering <- credit_data[, c("Limited_Bal", "Repay_Apr", "Repay_May", "Repay_Jun", "Repay_Jul", "Repay_Aug", "Repay_Sept")]
# Step 3: Standardize the data
scaled_data <- scale(data_for_clustering)
# Step 4: Determine optimal number of clusters using elbow method
wss <- (nrow(scaled_data)-1) * sum(apply(scaled_data, 2, var))
for (i in 2:15) wss[i] <- sum(kmeans(scaled_data, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
# Step 5: Based on the elbow plot, select the number of clusters (e.g., 3)
num_clusters <- 3
# Step 6: Perform K-means clustering
kmeans_result <- kmeans(scaled_data, centers=num_clusters)
# Step 7: Assign cluster labels to each user
cluster_labels <- kmeans_result$cluster
# Step 8: Add cluster labels to the original dataset
credit_data_with_clusters <- cbind(credit_data, cluster = cluster_labels)
# Step 9: Get the cluster centers
cluster_centers <- kmeans_result$centers
# Step 10: Calculate standard deviations across columns
col_std_dev <- apply(data_for_clustering, 2, sd)
# Step 11: Scale the cluster centers by dividing by standard deviations
cluster_centers <- scale(cluster_centers, center = FALSE, scale = col_std_dev)
# Step 12: Assign column names to cluster_centers
colnames(cluster_centers) <- colnames(data_for_clustering)
# Step 13: View cluster centers
print(cluster_centers)
# Visualization (Optional):
# Plot clusters based on the first two principal components
pca_data <- prcomp(scaled_data, center = TRUE, scale. = TRUE)
plot(pca_data$x[, 1], pca_data$x[, 2], col = cluster_labels, pch = 20, main = "Clusters based on Credit Utilization Patterns", xlab = "Principal Component 1", ylab = "Principal Component 2")
legend("topright", legend = unique(cluster_labels), col = unique(cluster_labels), pch = 20, title = "Cluster")
# Bar plot of default_payment_next_month
ggplot(final_data, aes(x = default_payment_next_month, fill = default_payment_next_month)) +
geom_bar() +
labs(title = "Default Payment Status",
x = "Default Payment Next Month",
y = "Count") +
theme(legend.position = "none")
